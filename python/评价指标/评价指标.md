## metric

混淆矩阵：常用于类别不平衡问题，当然一般问题也能用
<img src="G:\HelpDocs\评价指标\混淆矩阵.png" alt="avator"  />
混淆矩阵一家
![avator](G:\HelpDocs\评价指标\metrics.png)

* ACC：精确度，希望它较高
* Precision：精准率/查准率，希望它较高
* Recall：召回率/查全率，希望它较高
* F1-Score：precision和recall的一个计算式子，越接近于1效果越好。
* PR曲线：纵轴为precision，横轴为recall，都关心正例，我们希望precision和recall值都较高，所以曲线越趋向于右上角，模型越好
* AP（Average precision）：PR曲线下的**面积**，有具体的公式
* MAP（Mean Average precision）：相当于求所有类别的AP的平均值
* TPR：真阳率，希望它较高
* FPR：假阳率，希望它较低
* ROC曲线（Receiver Operating Characteristic Cureve）：FPR做横轴，TPR做纵轴，即衡量不同分类阈值下TPR随FPR的变换情况，所以曲线越靠左上角，模型性能越好，即数值越大模型越好。
* AUC（Area Under Curve）：取值[0.5, 1]，ROC曲线下的**面积**，数值越大模型越好。

*[参考链接1](https://www.zhihu.com/question/30643044)
[参考链接2](https://www.cnblogs.com/shixiangwan/p/7215926.html)
另外还可以参考《西瓜书》第二章*

### sklearn中的编码方式

[参考链接](https://cloud.tencent.com/developer/article/1913464)

#### 如何使用那条曲线那评价模型

       因为 ROC 曲线跟准确率/召回率曲线（或者叫 PR）很类似，如何决定使用哪一个曲线呢？当正例很少，或者当你关注假正例多于假反例的时候，优先使用 PR 曲线。其他情况使用 ROC 曲线。
    
       举例子，回顾前面的 ROC 曲线和 ROC AUC 数值，你或许认为这个分类器很棒。但是这几乎全是因为只有少数正例（“是 5”），而大部分是反例（“非 5”）。相反，PR 曲线清楚显示出这个分类器还有很大的改善空间（PR 曲线应该尽可能地靠近右上角）。


